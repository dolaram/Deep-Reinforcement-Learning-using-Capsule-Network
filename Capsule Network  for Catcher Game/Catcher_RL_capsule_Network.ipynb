{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cn1lab005/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import time \n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "import pygame\n",
    "from ple import PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ple.games.catcher import Catcher\n",
    "#game = Catcher()\n",
    "game = Catcher(width=256, height=256)\n",
    "game.screen = pygame.display.set_mode(game.getScreenDims(), 0, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME  = \"CATCHER\"\n",
    "ACTIONS = 3 # number of valid actions\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVE = 500. # timesteps to observe before training\n",
    "EXPLORE = 500. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON =  0.05 # final value of epsilon\n",
    "INITIAL_EPSILON = 1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "FRAME_PER_ACTION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-9\n",
    "iter_routing = 2\n",
    "train_freq = 10\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector):\n",
    "    vec_squared_norm = reduce_sum(tf.square(vector), -2, keepdims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    vec_squashed = scalar_factor * vector  # element-wise\n",
    "    return(vec_squashed)\n",
    "def reduce_sum(input_tensor, axis=None, keepdims=False):\n",
    "    return tf.reduce_sum(input_tensor, axis=axis, keepdims=keepdims)\n",
    "def softmax(logits, axis=None):\n",
    "    return tf.nn.softmax(logits, axis=axis)\n",
    "def routing(input, b_IJ):\n",
    "    # W: [1, num_caps_i, num_caps_j * len_v_j, len_u_j, 1]\n",
    "    W = tf.get_variable('Weight', shape=(1, 32, 50, 5, 1), dtype=tf.float32,\n",
    "                        initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "    biases = tf.get_variable('bias', shape=(1, 1, 10, 5, 1))\n",
    "    # A better solution is using element-wise multiply, reduce_sum and reshape\n",
    "    # ops instead. Matmul [a, b] x [b, c] is equal to a series ops as\n",
    "    # element-wise multiply [a*c, b] * [a*c, b], reduce_sum at axis=1 and\n",
    "    # reshape to [a, c]\n",
    "    input = tf.tile(input, [1, 1, 50, 1, 1])\n",
    "    #assert input.get_shape() == [cfg.batch_size, 1024, 160, 8, 1]\n",
    "\n",
    "    u_hat = reduce_sum(W * input, axis=3, keepdims=True)\n",
    "    u_hat = tf.reshape(u_hat, shape=[-1, 32, 10, 5, 1])\n",
    "    #assert u_hat.get_shape() == [cfg.batch_size, 1024, 10, 16, 1]\n",
    "\n",
    "    # In forward, u_hat_stopped = u_hat; in backward, no gradient passed back from u_hat_stopped to u_hat\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "\n",
    "    # line 3,for r iterations do\n",
    "    for r_iter in range(iter_routing):\n",
    "        with tf.variable_scope('iter_' + str(r_iter)):\n",
    "            # line 4:\n",
    "            # => [batch_size, 1024, 10, 1, 1]\n",
    "            c_IJ = softmax(b_IJ, axis=2)\n",
    "\n",
    "            # At last iteration, use `u_hat` in order to receive gradients from the following graph\n",
    "            if r_iter == iter_routing - 1:\n",
    "                # line 5:\n",
    "                # weighting u_hat with c_IJ, element-wise in the last two dims\n",
    "                # => [batch_size, 1024, 10, 16, 1]\n",
    "                s_J = tf.multiply(c_IJ, u_hat)\n",
    "                # then sum in the second dim, resulting in [batch_size, 1, 10, 16, 1]\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "                #assert s_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "\n",
    "                # line 6:\n",
    "                # squash using Eq.1,\n",
    "                v_J = squash(s_J)\n",
    "                #assert v_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "            elif r_iter < iter_routing - 1:  # Inner iterations, do not apply backpropagation\n",
    "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "                v_J = squash(s_J)\n",
    "\n",
    "                # line 7:\n",
    "                # reshape & tile v_j from [batch_size ,1, 10, 16, 1] to [batch_size, 1024, 10, 16, 1]\n",
    "                # then matmul in the last tow dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
    "                # batch_size dim, resulting in [1, 1024, 10, 1, 1]\n",
    "                v_J_tiled = tf.tile(v_J, [1, 32, 1, 1, 1])\n",
    "                u_produce_v = reduce_sum(u_hat_stopped * v_J_tiled, axis=3, keepdims=True)\n",
    "                #assert u_produce_v.get_shape() == [cfg.batch_size, 1024, 10, 1, 1]\n",
    "\n",
    "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
    "                b_IJ += u_produce_v\n",
    "    return(v_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetwork():\n",
    "    s= tf.placeholder(\"float\", [None, 28, 28, 4])\n",
    "    coeff = tf.placeholder(tf.float32, shape=(None, 32, 10, 1, 1))\n",
    "    ####################### New Network COnfiguration #####################    \n",
    "    w_initializer, b_initializer = tf.random_normal_initializer(0., 0.01), tf.constant_initializer(0.01)\n",
    "    w1 = tf.get_variable('w1',[6, 6, 4, 16],initializer=w_initializer)\n",
    "    b1 = tf.get_variable('b1',[16],initializer=b_initializer)\n",
    "\n",
    "    l1 = tf.nn.conv2d(s, w1, strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(l1, b1))\n",
    "    #print(\"stu\",conv1)\n",
    "    conv1 = tf.reshape(conv1,[-1,12,12,16])\n",
    "    #print(conv1)\n",
    "\n",
    "    capsules1 = tf.contrib.layers.conv2d(conv1, 10, kernel_size=6, stride=2, padding=\"VALID\",\n",
    "                    activation_fn = tf.nn.relu,\n",
    "                    weights_initializer = tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                    biases_initializer=tf.constant_initializer(0))\n",
    "    #print(capsules1,\"jhg\")\n",
    "\n",
    "    capsules = tf.reshape(capsules1, (-1, 32, 5, 1)) #Reshape to(batch_szie, 1152, 8, 1)\n",
    "    #print(capsules)\n",
    "    capsules = squash(capsules)\n",
    "    #print(capsules)\n",
    "\n",
    "    input_caps2 = tf.reshape(capsules, shape=(-1, 32, 1, capsules.shape[-2].value, 1))\n",
    "    #print(capsules)\n",
    "\n",
    "    caps2 = routing(input_caps2, coeff)\n",
    "    #print(caps2)\n",
    "\n",
    "    vector_j = tf.reshape(caps2, shape=(-1, 50))\n",
    "    #print(vector_j)\n",
    "    q_eval = tf.contrib.layers.fully_connected(vector_j, num_outputs=ACTIONS, activation_fn=None)\n",
    "    #print(q_eval)\n",
    "    readout = q_eval\n",
    "    return s, coeff, readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNetwork(s, coeff, readout, sess):\n",
    "    tick = time.time()\n",
    "    # define the cost function\n",
    "    a = tf.placeholder(\"float\", [None, ACTIONS])\n",
    "    y = tf.placeholder(\"float\", [None])\n",
    "    readout_action = tf.reduce_sum(tf.multiply(readout, a), reduction_indices = 1)\n",
    "    cost = tf.reduce_mean(tf.square(y - readout_action))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "    ## open up a game state to communicate with emulator\n",
    "    # game_state = game.GameState()\n",
    "    p =  PLE(game,display_screen=True)\n",
    "    actions = p.getActionSet()\n",
    "    p.init()\n",
    "    reward = p.act(p.NOOP)\n",
    "    \n",
    "    # store the previous observations in replay memory\n",
    "    D = deque()\n",
    "    \n",
    "    # get the first state by doing nothing and preprocess the image to 80x80x4\n",
    "    \n",
    "    action_index =  np.random.randint(0, 3)\n",
    "    reward = p.act(actions[action_index])\n",
    "    if(reward != 0):\n",
    "        if(reward < -1):\n",
    "            r_0 = -1\n",
    "        else:\n",
    "            r_0 = reward\n",
    "        terminal = 1\n",
    "        if(np.max(readout_t) > qmax):\n",
    "            qmax = np.max(readout_t) \n",
    "        print(\"time_step\", t,\"/SCORE\", score,\"/rt\", r_t,\"/ Q_MAX %e\" % qmax)\n",
    "        qmax = -10000\n",
    "    else:\n",
    "        terminal = 0\n",
    "        r_0 = reward\n",
    "            \n",
    "    x_t = p.getScreenRGB()\n",
    "    x_t = cv2.cvtColor(cv2.resize(x_t, (28, 28)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # saving and loading networks\n",
    "    saver = tf.train.Saver()\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_networks\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Could not find old network weights\")\n",
    "    b_IJ1 = np.zeros((1, 32, 10, 1, 1)).astype(np.float32) # batch_size=1\n",
    "    b_IJ2 = np.zeros((BATCH, 32, 10, 1, 1)).astype(np.float32) # batch_size=BATCH\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    t = 0\n",
    "    score = 0\n",
    "    qmax = -100000\n",
    "    tick = time.time()\n",
    "    while True:\n",
    "        # choose an action epsilon greedily\n",
    "        readout_t = readout.eval(feed_dict = {s:s_t.reshape((1,28,28,4)), coeff:b_IJ1})\n",
    "        \n",
    "        a_t = np.zeros([ACTIONS])\n",
    "        action_index = 0\n",
    "        if random.random() <= epsilon or t <= OBSERVE:\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "            a_t[action_index] = 1\n",
    "        else:\n",
    "            action_index = np.argmax(readout_t)\n",
    "            a_t[action_index] = 1\n",
    "\n",
    "        # scale down epsilon\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "        # run the selected action and observe next state and reward\n",
    "        reward = p.act(actions[action_index])\n",
    "        if(reward != 0):\n",
    "            if(reward < -1):\n",
    "                r_t = -1\n",
    "            else:\n",
    "                r_t = reward\n",
    "            terminal = 1\n",
    "            if(np.max(readout_t) > qmax):\n",
    "                qmax = np.max(readout_t) \n",
    "            print(\"time_step\", t,\"/SCORE\", score,\"/rt\", r_t,\"/ Q_MAX %e\" % qmax)\n",
    "            qmax = -10000\n",
    "        else:\n",
    "            terminal = 0\n",
    "            r_t = reward\n",
    "        # run the selected action and observe next state and reward\n",
    "        x_t1_colored = p.getScreenRGB()\n",
    "        x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (28, 28)), cv2.COLOR_BGR2GRAY)\n",
    "        ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "        x_t1 = np.reshape(x_t1, (28, 28, 1))\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :3], axis=2)\n",
    "        # store the transition in D\n",
    "        D.append((s_t, a_t, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "        \n",
    "        # only train if done observing\n",
    "        if t > OBSERVE and t%train_freq==0:\n",
    "            # sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "\n",
    "            # get the batch variables\n",
    "            s_j_batch = [d[0] for d in minibatch]\n",
    "            a_batch = [d[1] for d in minibatch]\n",
    "            r_batch = [d[2] for d in minibatch]\n",
    "            s_j1_batch = [d[3] for d in minibatch]\n",
    "\n",
    "            y_batch = []\n",
    "            readout_j1_batch = readout.eval(feed_dict = {s:s_j1_batch, coeff:b_IJ2 })\n",
    "            #readout_j1_batch = readout.eval(feed_dict = {s : s_j1_batch})\n",
    "            for i in range(0, len(minibatch)):\n",
    "                # if terminal only equals reward\n",
    "                if minibatch[i][4]:\n",
    "                    y_batch.append(r_batch[i])\n",
    "                else:\n",
    "                    y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i]))\n",
    "\n",
    "            # perform gradient step\n",
    "            train_step.run(feed_dict = {\n",
    "                y : y_batch,\n",
    "                a : a_batch,\n",
    "                s : s_j_batch,\n",
    "                coeff: b_IJ2})\n",
    "            loss = cost.eval(feed_dict = {\n",
    "                y : y_batch,\n",
    "                a : a_batch,\n",
    "                s : s_j_batch,\n",
    "                coeff: b_IJ2})\n",
    "\n",
    "        # update the old values\n",
    "        s_t = s_t1\n",
    "        t += 1\n",
    "        \n",
    "        # save progress every 10000 iterations\n",
    "        #if t % 10000 == 0:\n",
    "        #    saver.save(sess, 'saved_networks/' + GAME + '-dqn', global_step = t)\n",
    "\n",
    "        score += reward\n",
    "        if p.game_over():\n",
    "            p.reset_game()\n",
    "            #print(\"time_step:\",t,\"score:\",score)\n",
    "            score = 0\n",
    "        #vars = tf.trainable_variables()\n",
    "        #vars_vals = sess.run(vars)\n",
    "        #print(vars_vals)\n",
    "        #return vars_vals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_networks/CATCHER-dqn-40000\n",
      "Successfully loaded: saved_networks/CATCHER-dqn-40000\n",
      "time_step 41 /SCORE 0 /rt 1.0 / Q_MAX -2.079601e-02\n",
      "time_step 77 /SCORE 1.0 /rt -1.0 / Q_MAX -2.246365e+00\n",
      "time_step 118 /SCORE 0.0 /rt -1.0 / Q_MAX -2.800973e+00\n",
      "time_step 164 /SCORE -1.0 /rt -1 / Q_MAX -2.651603e+00\n",
      "time_step 199 /SCORE 0.0 /rt 1.0 / Q_MAX -1.549535e-01\n",
      "time_step 235 /SCORE 1.0 /rt 1.0 / Q_MAX 9.501515e-01\n",
      "time_step 274 /SCORE 2.0 /rt -1.0 / Q_MAX -2.353255e+00\n",
      "time_step 310 /SCORE 1.0 /rt -1.0 / Q_MAX -2.157486e+00\n",
      "time_step 353 /SCORE 0.0 /rt 1.0 / Q_MAX -7.733086e-01\n",
      "time_step 389 /SCORE 1.0 /rt -1 / Q_MAX -2.134864e+00\n",
      "time_step 421 /SCORE 0.0 /rt 1.0 / Q_MAX 9.334372e-01\n",
      "time_step 464 /SCORE 1.0 /rt 1.0 / Q_MAX -6.126940e-01\n",
      "time_step 500 /SCORE 2.0 /rt -1.0 / Q_MAX -2.540221e+00\n",
      "time_step 546 /SCORE 1.0 /rt -1.0 / Q_MAX -8.309834e-01\n",
      "time_step 582 /SCORE 0.0 /rt -1 / Q_MAX -2.274508e+00\n",
      "time_step 624 /SCORE 0.0 /rt 1.0 / Q_MAX -6.461035e-01\n",
      "time_step 661 /SCORE 1.0 /rt -1.0 / Q_MAX -2.393700e+00\n",
      "time_step 695 /SCORE 0.0 /rt -1.0 / Q_MAX -1.457789e+00\n",
      "time_step 731 /SCORE -1.0 /rt 1.0 / Q_MAX 7.793518e-01\n",
      "time_step 767 /SCORE 0.0 /rt -1 / Q_MAX -1.295862e+00\n",
      "time_step 805 /SCORE 0.0 /rt -1.0 / Q_MAX -9.758954e-01\n",
      "time_step 839 /SCORE -1.0 /rt -1.0 / Q_MAX -1.251386e+00\n",
      "time_step 885 /SCORE -2.0 /rt -1 / Q_MAX -5.555438e-01\n",
      "time_step 920 /SCORE 0.0 /rt 1.0 / Q_MAX 3.470203e-01\n",
      "time_step 953 /SCORE 1.0 /rt 1.0 / Q_MAX 8.880385e-01\n",
      "time_step 994 /SCORE 2.0 /rt 1.0 / Q_MAX 8.846066e-01\n",
      "time_step 1033 /SCORE 3.0 /rt 1.0 / Q_MAX 1.165601e+00\n",
      "time_step 1069 /SCORE 4.0 /rt 1.0 / Q_MAX 4.025777e-02\n",
      "time_step 1110 /SCORE 5.0 /rt 1.0 / Q_MAX 7.264587e-01\n",
      "time_step 1144 /SCORE 6.0 /rt -1.0 / Q_MAX -9.629608e-01\n",
      "time_step 1188 /SCORE 5.0 /rt -1.0 / Q_MAX -1.009170e+00\n",
      "time_step 1226 /SCORE 4.0 /rt 1.0 / Q_MAX 4.370303e-01\n",
      "time_step 1269 /SCORE 5.0 /rt 1.0 / Q_MAX 7.534277e-01\n",
      "time_step 1313 /SCORE 6.0 /rt 1.0 / Q_MAX 5.867881e-01\n",
      "time_step 1349 /SCORE 7.0 /rt 1.0 / Q_MAX 8.094138e-01\n",
      "time_step 1380 /SCORE 8.0 /rt 1.0 / Q_MAX 6.488227e-01\n",
      "time_step 1421 /SCORE 9.0 /rt 1.0 / Q_MAX -1.714908e-01\n",
      "time_step 1464 /SCORE 10.0 /rt 1.0 / Q_MAX 8.934368e-01\n",
      "time_step 1498 /SCORE 11.0 /rt 1.0 / Q_MAX 9.424601e-01\n",
      "time_step 1531 /SCORE 12.0 /rt 1.0 / Q_MAX 1.015874e+00\n",
      "time_step 1562 /SCORE 13.0 /rt 1.0 / Q_MAX 1.238366e+00\n",
      "time_step 1596 /SCORE 14.0 /rt 1.0 / Q_MAX 1.239510e+00\n",
      "time_step 1637 /SCORE 15.0 /rt 1.0 / Q_MAX 1.074219e+00\n",
      "time_step 1671 /SCORE 16.0 /rt 1.0 / Q_MAX 8.063361e-01\n",
      "time_step 1705 /SCORE 17.0 /rt 1.0 / Q_MAX 7.460039e-01\n",
      "time_step 1739 /SCORE 18.0 /rt 1.0 / Q_MAX 7.489280e-01\n",
      "time_step 1780 /SCORE 19.0 /rt 1.0 / Q_MAX 9.360084e-01\n",
      "time_step 1816 /SCORE 20.0 /rt 1.0 / Q_MAX 1.242070e+00\n",
      "time_step 1855 /SCORE 21.0 /rt 1.0 / Q_MAX 1.255164e+00\n",
      "time_step 1893 /SCORE 22.0 /rt 1.0 / Q_MAX 1.038400e+00\n",
      "time_step 1931 /SCORE 23.0 /rt 1.0 / Q_MAX 4.757736e-01\n",
      "time_step 1975 /SCORE 24.0 /rt -1 / Q_MAX -1.404325e+00\n",
      "time_step 2010 /SCORE 0.0 /rt 1.0 / Q_MAX 1.051811e+00\n",
      "time_step 2049 /SCORE 1.0 /rt 1.0 / Q_MAX 8.674929e-01\n",
      "time_step 2080 /SCORE 2.0 /rt 1.0 / Q_MAX 1.376468e+00\n",
      "time_step 2121 /SCORE 3.0 /rt 1.0 / Q_MAX 1.107457e+00\n",
      "time_step 2157 /SCORE 4.0 /rt 1.0 / Q_MAX 1.254092e+00\n",
      "time_step 2196 /SCORE 5.0 /rt 1.0 / Q_MAX 8.733162e-01\n",
      "time_step 2232 /SCORE 6.0 /rt -1.0 / Q_MAX 6.858301e-01\n",
      "time_step 2271 /SCORE 5.0 /rt 1.0 / Q_MAX 1.276937e+00\n",
      "time_step 2302 /SCORE 6.0 /rt 1.0 / Q_MAX 9.532226e-01\n",
      "time_step 2341 /SCORE 7.0 /rt 1.0 / Q_MAX 1.242076e+00\n",
      "time_step 2379 /SCORE 8.0 /rt 1.0 / Q_MAX 1.010562e+00\n",
      "time_step 2418 /SCORE 9.0 /rt 1.0 / Q_MAX 8.740873e-01\n",
      "time_step 2454 /SCORE 10.0 /rt 1.0 / Q_MAX 1.236900e+00\n",
      "time_step 2489 /SCORE 11.0 /rt 1.0 / Q_MAX 8.080292e-01\n",
      "time_step 2531 /SCORE 12.0 /rt -1.0 / Q_MAX -7.325561e-02\n",
      "time_step 2574 /SCORE 11.0 /rt 1.0 / Q_MAX 1.082951e+00\n",
      "time_step 2609 /SCORE 12.0 /rt 1.0 / Q_MAX 8.406773e-01\n",
      "time_step 2651 /SCORE 13.0 /rt -1 / Q_MAX -2.331377e-01\n",
      "time_step 2689 /SCORE 0.0 /rt -1.0 / Q_MAX -4.496683e-01\n",
      "time_step 2722 /SCORE -1.0 /rt 1.0 / Q_MAX 1.085306e+00\n",
      "time_step 2756 /SCORE 0.0 /rt 1.0 / Q_MAX 1.284777e+00\n",
      "time_step 2787 /SCORE 1.0 /rt 1.0 / Q_MAX 1.300305e+00\n",
      "time_step 2823 /SCORE 2.0 /rt -1.0 / Q_MAX -1.250191e-01\n",
      "time_step 2862 /SCORE 1.0 /rt 1.0 / Q_MAX 1.137139e+00\n",
      "time_step 2907 /SCORE 2.0 /rt 1.0 / Q_MAX 8.980632e-01\n",
      "time_step 2938 /SCORE 3.0 /rt 1.0 / Q_MAX 9.593432e-01\n",
      "time_step 2971 /SCORE 4.0 /rt 1.0 / Q_MAX 9.495764e-01\n",
      "time_step 3010 /SCORE 5.0 /rt 1.0 / Q_MAX 1.235086e+00\n",
      "time_step 3045 /SCORE 6.0 /rt 1.0 / Q_MAX 9.827731e-01\n",
      "time_step 3082 /SCORE 7.0 /rt -1 / Q_MAX 2.601465e-01\n",
      "time_step 3119 /SCORE 0.0 /rt 1.0 / Q_MAX 1.069782e+00\n",
      "time_step 3160 /SCORE 1.0 /rt 1.0 / Q_MAX 1.140209e+00\n",
      "time_step 3204 /SCORE 2.0 /rt -1.0 / Q_MAX -3.076148e-01\n",
      "time_step 3237 /SCORE 1.0 /rt 1.0 / Q_MAX 1.116748e+00\n",
      "time_step 3283 /SCORE 2.0 /rt -1.0 / Q_MAX 2.570155e-01\n",
      "time_step 3319 /SCORE 1.0 /rt 1.0 / Q_MAX 1.268402e+00\n",
      "time_step 3355 /SCORE 2.0 /rt 1.0 / Q_MAX 1.349122e+00\n",
      "time_step 3386 /SCORE 3.0 /rt 1.0 / Q_MAX 1.347305e+00\n",
      "time_step 3427 /SCORE 4.0 /rt -1 / Q_MAX -7.528421e-02\n",
      "time_step 3467 /SCORE 0.0 /rt 1.0 / Q_MAX 9.621758e-01\n",
      "time_step 3508 /SCORE 1.0 /rt 1.0 / Q_MAX 1.019758e+00\n",
      "time_step 3549 /SCORE 2.0 /rt 1.0 / Q_MAX 1.123858e+00\n",
      "time_step 3595 /SCORE 3.0 /rt -1.0 / Q_MAX 6.925846e-01\n",
      "time_step 3641 /SCORE 2.0 /rt -1.0 / Q_MAX 6.937029e-01\n",
      "time_step 3674 /SCORE 1.0 /rt 1.0 / Q_MAX 8.316736e-01\n",
      "time_step 3710 /SCORE 2.0 /rt 1.0 / Q_MAX 5.726877e-01\n",
      "time_step 3754 /SCORE 3.0 /rt -1 / Q_MAX -1.063368e+00\n",
      "time_step 3799 /SCORE 0.0 /rt -1.0 / Q_MAX -1.004345e+00\n",
      "time_step 3841 /SCORE -1.0 /rt 1.0 / Q_MAX 8.523403e-01\n",
      "time_step 3880 /SCORE 0.0 /rt 1.0 / Q_MAX 1.146838e+00\n",
      "time_step 3922 /SCORE 1.0 /rt -1.0 / Q_MAX -5.302833e-02\n",
      "time_step 3961 /SCORE 0.0 /rt 1.0 / Q_MAX 1.271261e+00\n",
      "time_step 3997 /SCORE 1.0 /rt 1.0 / Q_MAX 6.027458e-01\n",
      "time_step 4039 /SCORE 2.0 /rt -1 / Q_MAX -1.997320e-01\n",
      "time_step 4073 /SCORE 0.0 /rt 1.0 / Q_MAX -3.049377e-01\n",
      "time_step 4106 /SCORE 1.0 /rt 1.0 / Q_MAX 1.037943e+00\n",
      "time_step 4147 /SCORE 2.0 /rt 1.0 / Q_MAX 1.247050e+00\n",
      "time_step 4181 /SCORE 3.0 /rt 1.0 / Q_MAX 1.284114e+00\n",
      "time_step 4214 /SCORE 4.0 /rt 1.0 / Q_MAX 1.185330e+00\n",
      "time_step 4257 /SCORE 5.0 /rt 1.0 / Q_MAX 1.223554e+00\n",
      "time_step 4291 /SCORE 6.0 /rt 1.0 / Q_MAX 1.249805e+00\n",
      "time_step 4324 /SCORE 7.0 /rt 1.0 / Q_MAX 1.308143e+00\n",
      "time_step 4358 /SCORE 8.0 /rt 1.0 / Q_MAX 8.992261e-01\n",
      "time_step 4395 /SCORE 9.0 /rt -1.0 / Q_MAX 5.310245e-01\n",
      "time_step 4428 /SCORE 8.0 /rt 1.0 / Q_MAX 6.020707e-01\n",
      "time_step 4460 /SCORE 9.0 /rt 1.0 / Q_MAX -3.353147e-01\n",
      "time_step 4502 /SCORE 10.0 /rt -1.0 / Q_MAX -3.788257e-02\n",
      "time_step 4544 /SCORE 9.0 /rt -1 / Q_MAX 4.278718e-01\n",
      "time_step 4581 /SCORE 0.0 /rt 1.0 / Q_MAX 1.352358e+00\n",
      "time_step 4620 /SCORE 1.0 /rt 1.0 / Q_MAX 1.260255e+00\n",
      "time_step 4654 /SCORE 2.0 /rt 1.0 / Q_MAX 3.719130e-01\n",
      "time_step 4697 /SCORE 3.0 /rt 1.0 / Q_MAX 1.121712e+00\n",
      "time_step 4735 /SCORE 4.0 /rt 1.0 / Q_MAX 1.365165e+00\n",
      "time_step 4774 /SCORE 5.0 /rt 1.0 / Q_MAX 9.217639e-01\n",
      "time_step 4808 /SCORE 6.0 /rt 1.0 / Q_MAX 1.279957e+00\n",
      "time_step 4844 /SCORE 7.0 /rt -1.0 / Q_MAX 1.766933e-01\n",
      "time_step 4875 /SCORE 6.0 /rt 1.0 / Q_MAX 8.226246e-01\n",
      "time_step 4919 /SCORE 7.0 /rt -1.0 / Q_MAX 3.371857e-01\n",
      "time_step 4950 /SCORE 6.0 /rt 1.0 / Q_MAX 1.269960e+00\n",
      "time_step 4990 /SCORE 7.0 /rt 1.0 / Q_MAX 7.163189e-01\n",
      "time_step 5031 /SCORE 8.0 /rt 1.0 / Q_MAX 1.250860e+00\n",
      "time_step 5072 /SCORE 9.0 /rt -1 / Q_MAX -1.833409e-01\n",
      "time_step 5106 /SCORE 0.0 /rt 1.0 / Q_MAX 1.103998e+00\n",
      "time_step 5145 /SCORE 1.0 /rt 1.0 / Q_MAX 1.296544e+00\n",
      "time_step 5186 /SCORE 2.0 /rt 1.0 / Q_MAX 1.134614e+00\n",
      "time_step 5227 /SCORE 3.0 /rt 1.0 / Q_MAX 1.259306e+00\n",
      "time_step 5261 /SCORE 4.0 /rt 1.0 / Q_MAX 8.243745e-01\n",
      "time_step 5292 /SCORE 5.0 /rt 1.0 / Q_MAX 1.030536e+00\n",
      "time_step 5338 /SCORE 6.0 /rt -1.0 / Q_MAX 1.452760e-01\n",
      "time_step 5377 /SCORE 5.0 /rt 1.0 / Q_MAX 1.259684e+00\n",
      "time_step 5411 /SCORE 6.0 /rt 1.0 / Q_MAX 8.494942e-01\n",
      "time_step 5450 /SCORE 7.0 /rt 1.0 / Q_MAX 1.256338e+00\n",
      "time_step 5489 /SCORE 8.0 /rt 1.0 / Q_MAX 1.165082e+00\n",
      "time_step 5525 /SCORE 9.0 /rt 1.0 / Q_MAX 1.245306e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_step 5568 /SCORE 10.0 /rt 1.0 / Q_MAX 9.388728e-01\n",
      "time_step 5601 /SCORE 11.0 /rt 1.0 / Q_MAX 1.178648e+00\n",
      "time_step 5634 /SCORE 12.0 /rt 1.0 / Q_MAX 7.336274e-01\n",
      "time_step 5673 /SCORE 13.0 /rt 1.0 / Q_MAX -3.465714e-01\n",
      "time_step 5709 /SCORE 14.0 /rt 1.0 / Q_MAX 9.843141e-01\n",
      "time_step 5748 /SCORE 15.0 /rt 1.0 / Q_MAX 9.611741e-01\n",
      "time_step 5787 /SCORE 16.0 /rt 1.0 / Q_MAX 1.280342e+00\n",
      "time_step 5823 /SCORE 17.0 /rt 1.0 / Q_MAX 1.374329e+00\n",
      "time_step 5859 /SCORE 18.0 /rt 1.0 / Q_MAX 1.263838e+00\n",
      "time_step 5902 /SCORE 19.0 /rt 1.0 / Q_MAX 9.431718e-01\n",
      "time_step 5943 /SCORE 20.0 /rt 1.0 / Q_MAX 5.805961e-01\n",
      "time_step 5976 /SCORE 21.0 /rt 1.0 / Q_MAX 1.099847e+00\n",
      "time_step 6010 /SCORE 22.0 /rt 1.0 / Q_MAX 1.249258e+00\n",
      "time_step 6054 /SCORE 23.0 /rt -1.0 / Q_MAX -7.663337e-03\n",
      "time_step 6087 /SCORE 22.0 /rt 1.0 / Q_MAX 1.095211e+00\n",
      "time_step 6124 /SCORE 23.0 /rt -1 / Q_MAX 8.045769e-01\n",
      "time_step 6159 /SCORE 0.0 /rt -1.0 / Q_MAX -4.550495e-01\n",
      "time_step 6202 /SCORE -1.0 /rt 1.0 / Q_MAX 9.742743e-01\n",
      "time_step 6248 /SCORE 0.0 /rt -1.0 / Q_MAX 7.506729e-01\n",
      "time_step 6284 /SCORE -1.0 /rt 1.0 / Q_MAX 1.362449e+00\n",
      "time_step 6319 /SCORE 0.0 /rt 1.0 / Q_MAX 5.889769e-01\n",
      "time_step 6353 /SCORE 1.0 /rt 1.0 / Q_MAX 1.209667e+00\n",
      "time_step 6394 /SCORE 2.0 /rt 1.0 / Q_MAX 1.246670e+00\n",
      "time_step 6435 /SCORE 3.0 /rt 1.0 / Q_MAX 1.257213e+00\n",
      "time_step 6471 /SCORE 4.0 /rt -1 / Q_MAX 6.523135e-01\n",
      "time_step 6510 /SCORE 0.0 /rt 1.0 / Q_MAX 9.053126e-01\n",
      "time_step 6546 /SCORE 1.0 /rt 1.0 / Q_MAX 7.499784e-01\n",
      "time_step 6584 /SCORE 2.0 /rt 1.0 / Q_MAX 1.116937e+00\n",
      "time_step 6620 /SCORE 3.0 /rt 1.0 / Q_MAX 1.340590e+00\n",
      "time_step 6662 /SCORE 4.0 /rt -1.0 / Q_MAX 7.149412e-02\n",
      "time_step 6708 /SCORE 3.0 /rt -1.0 / Q_MAX 6.868405e-01\n",
      "time_step 6739 /SCORE 2.0 /rt 1.0 / Q_MAX 1.334281e+00\n",
      "time_step 6780 /SCORE 3.0 /rt 1.0 / Q_MAX 1.228788e+00\n",
      "time_step 6814 /SCORE 4.0 /rt 1.0 / Q_MAX 8.873907e-01\n",
      "time_step 6855 /SCORE 5.0 /rt -1 / Q_MAX 4.023499e-01\n",
      "time_step 6895 /SCORE 0.0 /rt 1.0 / Q_MAX 9.254369e-01\n",
      "time_step 6928 /SCORE 1.0 /rt 1.0 / Q_MAX 8.645428e-01\n",
      "time_step 6971 /SCORE 2.0 /rt 1.0 / Q_MAX 1.161498e+00\n",
      "time_step 7010 /SCORE 3.0 /rt -1.0 / Q_MAX 7.367041e-04\n",
      "time_step 7041 /SCORE 2.0 /rt 1.0 / Q_MAX 1.037928e+00\n",
      "time_step 7075 /SCORE 3.0 /rt 1.0 / Q_MAX 1.159636e+00\n",
      "time_step 7110 /SCORE 4.0 /rt 1.0 / Q_MAX 6.758311e-01\n",
      "time_step 7141 /SCORE 5.0 /rt 1.0 / Q_MAX 1.144694e+00\n",
      "time_step 7174 /SCORE 6.0 /rt 1.0 / Q_MAX 1.212660e+00\n",
      "time_step 7213 /SCORE 7.0 /rt -1.0 / Q_MAX -5.539428e-01\n",
      "time_step 7249 /SCORE 6.0 /rt 1.0 / Q_MAX 9.139910e-01\n",
      "time_step 7290 /SCORE 7.0 /rt -1 / Q_MAX 6.017508e-01\n",
      "time_step 7324 /SCORE 0.0 /rt 1.0 / Q_MAX 1.170242e+00\n",
      "time_step 7359 /SCORE 1.0 /rt 1.0 / Q_MAX 7.305647e-01\n",
      "time_step 7398 /SCORE 2.0 /rt -1.0 / Q_MAX -5.152632e-01\n",
      "time_step 7439 /SCORE 1.0 /rt 1.0 / Q_MAX 1.168072e+00\n",
      "time_step 7480 /SCORE 2.0 /rt 1.0 / Q_MAX 9.813015e-01\n",
      "time_step 7523 /SCORE 3.0 /rt 1.0 / Q_MAX 1.119324e+00\n",
      "time_step 7559 /SCORE 4.0 /rt 1.0 / Q_MAX 9.829644e-01\n",
      "time_step 7597 /SCORE 5.0 /rt 1.0 / Q_MAX 5.239807e-01\n",
      "time_step 7633 /SCORE 6.0 /rt 1.0 / Q_MAX 9.270539e-01\n",
      "time_step 7676 /SCORE 7.0 /rt 1.0 / Q_MAX -5.651171e-02\n",
      "time_step 7712 /SCORE 8.0 /rt 1.0 / Q_MAX 5.336163e-01\n",
      "time_step 7745 /SCORE 9.0 /rt 1.0 / Q_MAX 5.359653e-01\n",
      "time_step 7781 /SCORE 10.0 /rt 1.0 / Q_MAX 1.036806e+00\n",
      "time_step 7815 /SCORE 11.0 /rt -1.0 / Q_MAX 1.858639e-02\n",
      "time_step 7849 /SCORE 10.0 /rt 1.0 / Q_MAX 5.516505e-01\n",
      "time_step 7886 /SCORE 11.0 /rt -1 / Q_MAX 3.454013e-02\n",
      "time_step 7925 /SCORE 0.0 /rt 1.0 / Q_MAX 8.697585e-01\n",
      "time_step 7958 /SCORE 1.0 /rt 1.0 / Q_MAX 1.115407e+00\n",
      "time_step 7989 /SCORE 2.0 /rt 1.0 / Q_MAX 2.286201e-01\n",
      "time_step 8025 /SCORE 3.0 /rt -1.0 / Q_MAX 4.501863e-01\n",
      "time_step 8062 /SCORE 2.0 /rt 1.0 / Q_MAX 5.458113e-01\n",
      "time_step 8108 /SCORE 3.0 /rt -1.0 / Q_MAX 1.050010e-01\n",
      "time_step 8144 /SCORE 2.0 /rt 1.0 / Q_MAX 4.974320e-01\n",
      "time_step 8178 /SCORE 3.0 /rt 1.0 / Q_MAX 1.188756e+00\n",
      "time_step 8209 /SCORE 4.0 /rt 1.0 / Q_MAX 1.006131e+00\n",
      "time_step 8240 /SCORE 5.0 /rt 1.0 / Q_MAX 4.845628e-01\n",
      "time_step 8286 /SCORE 6.0 /rt -1 / Q_MAX 6.996834e-01\n",
      "time_step 8323 /SCORE 0.0 /rt 1.0 / Q_MAX 7.933116e-01\n",
      "time_step 8362 /SCORE 1.0 /rt 1.0 / Q_MAX 1.223203e+00\n",
      "time_step 8403 /SCORE 2.0 /rt -1.0 / Q_MAX 7.161801e-01\n",
      "time_step 8436 /SCORE 1.0 /rt 1.0 / Q_MAX 1.041218e+00\n",
      "time_step 8467 /SCORE 2.0 /rt 1.0 / Q_MAX 4.352313e-01\n",
      "time_step 8503 /SCORE 3.0 /rt 1.0 / Q_MAX 1.024810e+00\n",
      "time_step 8541 /SCORE 4.0 /rt 1.0 / Q_MAX 1.066757e+00\n",
      "time_step 8580 /SCORE 5.0 /rt -1.0 / Q_MAX -4.622094e-01\n",
      "time_step 8623 /SCORE 4.0 /rt 1.0 / Q_MAX 1.181796e+00\n",
      "time_step 8655 /SCORE 5.0 /rt 1.0 / Q_MAX 9.331477e-01\n",
      "time_step 8689 /SCORE 6.0 /rt 1.0 / Q_MAX 8.154550e-01\n",
      "time_step 8725 /SCORE 7.0 /rt 1.0 / Q_MAX 1.006157e+00\n",
      "time_step 8759 /SCORE 8.0 /rt 1.0 / Q_MAX 8.690535e-01\n",
      "time_step 8790 /SCORE 9.0 /rt 1.0 / Q_MAX 6.028801e-01\n",
      "time_step 8833 /SCORE 10.0 /rt 1.0 / Q_MAX 1.028927e+00\n",
      "time_step 8869 /SCORE 11.0 /rt 1.0 / Q_MAX 1.024816e+00\n",
      "time_step 8902 /SCORE 12.0 /rt 1.0 / Q_MAX 6.832794e-01\n",
      "time_step 8938 /SCORE 13.0 /rt 1.0 / Q_MAX 1.166394e+00\n",
      "time_step 8979 /SCORE 14.0 /rt -1 / Q_MAX 7.070532e-01\n",
      "time_step 9023 /SCORE 0.0 /rt 1.0 / Q_MAX 1.305031e+00\n",
      "time_step 9062 /SCORE 1.0 /rt -1.0 / Q_MAX -4.390539e-01\n",
      "time_step 9096 /SCORE 0.0 /rt 1.0 / Q_MAX 1.057873e+00\n",
      "time_step 9137 /SCORE 1.0 /rt 1.0 / Q_MAX 1.010356e+00\n",
      "time_step 9175 /SCORE 2.0 /rt 1.0 / Q_MAX 1.373125e+00\n",
      "time_step 9207 /SCORE 3.0 /rt 1.0 / Q_MAX 5.938217e-01\n",
      "time_step 9243 /SCORE 4.0 /rt 1.0 / Q_MAX 1.183758e+00\n",
      "time_step 9279 /SCORE 5.0 /rt 1.0 / Q_MAX 1.185183e+00\n",
      "time_step 9322 /SCORE 6.0 /rt 1.0 / Q_MAX 9.304897e-01\n",
      "time_step 9365 /SCORE 7.0 /rt 1.0 / Q_MAX 1.102918e+00\n",
      "time_step 9407 /SCORE 8.0 /rt 1.0 / Q_MAX 7.358689e-01\n",
      "time_step 9440 /SCORE 9.0 /rt 1.0 / Q_MAX 1.070417e+00\n",
      "time_step 9476 /SCORE 10.0 /rt -1.0 / Q_MAX 6.813074e-01\n",
      "time_step 9518 /SCORE 9.0 /rt -1 / Q_MAX -2.160272e-01\n",
      "time_step 9552 /SCORE 0.0 /rt 1.0 / Q_MAX 7.339824e-01\n",
      "time_step 9590 /SCORE 1.0 /rt 1.0 / Q_MAX 9.294403e-01\n",
      "time_step 9631 /SCORE 2.0 /rt 1.0 / Q_MAX 5.676972e-01\n",
      "time_step 9672 /SCORE 3.0 /rt 1.0 / Q_MAX 6.789908e-01\n",
      "time_step 9708 /SCORE 4.0 /rt 1.0 / Q_MAX 1.068631e+00\n",
      "time_step 9742 /SCORE 5.0 /rt -1.0 / Q_MAX -4.834218e-01\n",
      "time_step 9786 /SCORE 4.0 /rt 1.0 / Q_MAX 8.080968e-01\n",
      "time_step 9820 /SCORE 5.0 /rt -1.0 / Q_MAX -4.828475e-01\n",
      "time_step 9863 /SCORE 4.0 /rt 1.0 / Q_MAX 1.133033e+00\n",
      "time_step 9908 /SCORE 5.0 /rt 1.0 / Q_MAX 6.268679e-01\n",
      "time_step 9949 /SCORE 6.0 /rt -1 / Q_MAX 7.037364e-01\n",
      "time_step 9983 /SCORE 0.0 /rt 1.0 / Q_MAX 8.601429e-01\n",
      "time_step 10025 /SCORE 1.0 /rt -1.0 / Q_MAX 2.342146e-01\n",
      "time_step 10061 /SCORE 0.0 /rt -1.0 / Q_MAX 6.441385e-01\n",
      "time_step 10102 /SCORE -1.0 /rt 1.0 / Q_MAX 1.116771e+00\n",
      "time_step 10135 /SCORE 0.0 /rt 1.0 / Q_MAX 6.480973e-01\n",
      "time_step 10176 /SCORE 1.0 /rt 1.0 / Q_MAX 1.109374e+00\n",
      "time_step 10217 /SCORE 2.0 /rt -1 / Q_MAX 7.383701e-01\n",
      "time_step 10259 /SCORE 0.0 /rt 1.0 / Q_MAX 1.050039e+00\n",
      "time_step 10292 /SCORE 1.0 /rt 1.0 / Q_MAX 1.147007e+00\n",
      "time_step 10324 /SCORE 2.0 /rt 1.0 / Q_MAX 5.137722e-01\n",
      "time_step 10358 /SCORE 3.0 /rt -1.0 / Q_MAX -2.583373e-01\n",
      "time_step 10392 /SCORE 2.0 /rt -1.0 / Q_MAX -5.839069e-01\n",
      "time_step 10428 /SCORE 1.0 /rt -1 / Q_MAX 4.093197e-01\n",
      "time_step 10470 /SCORE 0.0 /rt 1.0 / Q_MAX 1.105102e+00\n",
      "time_step 10505 /SCORE 1.0 /rt 1.0 / Q_MAX 8.557202e-01\n",
      "time_step 10546 /SCORE 2.0 /rt 1.0 / Q_MAX 7.625139e-01\n",
      "time_step 10579 /SCORE 3.0 /rt 1.0 / Q_MAX 2.631893e-01\n",
      "time_step 10618 /SCORE 4.0 /rt 1.0 / Q_MAX 1.110018e+00\n",
      "time_step 10664 /SCORE 5.0 /rt -1.0 / Q_MAX -1.451347e-01\n",
      "time_step 10701 /SCORE 4.0 /rt -1.0 / Q_MAX 1.633751e-01\n",
      "time_step 10735 /SCORE 3.0 /rt 1.0 / Q_MAX 1.113459e+00\n",
      "time_step 10777 /SCORE 4.0 /rt 1.0 / Q_MAX 7.108476e-01\n",
      "time_step 10814 /SCORE 5.0 /rt -1 / Q_MAX 1.886094e-03\n",
      "time_step 10853 /SCORE 0.0 /rt 1.0 / Q_MAX 3.521391e-01\n",
      "time_step 10891 /SCORE 1.0 /rt 1.0 / Q_MAX 7.290752e-01\n",
      "time_step 10934 /SCORE 2.0 /rt 1.0 / Q_MAX 9.444705e-01\n",
      "time_step 10973 /SCORE 3.0 /rt 1.0 / Q_MAX 1.000526e+00\n",
      "time_step 11007 /SCORE 4.0 /rt 1.0 / Q_MAX 1.146168e+00\n",
      "time_step 11047 /SCORE 5.0 /rt 1.0 / Q_MAX 1.099786e+00\n",
      "time_step 11086 /SCORE 6.0 /rt 1.0 / Q_MAX 1.109040e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_step 11120 /SCORE 7.0 /rt 1.0 / Q_MAX 1.156063e+00\n",
      "time_step 11156 /SCORE 8.0 /rt 1.0 / Q_MAX 7.852602e-01\n",
      "time_step 11194 /SCORE 9.0 /rt 1.0 / Q_MAX 1.106652e+00\n",
      "time_step 11228 /SCORE 10.0 /rt -1.0 / Q_MAX 5.244451e-01\n",
      "time_step 11267 /SCORE 9.0 /rt 1.0 / Q_MAX 6.722974e-01\n",
      "time_step 11310 /SCORE 10.0 /rt 1.0 / Q_MAX 5.948424e-01\n",
      "time_step 11341 /SCORE 11.0 /rt 1.0 / Q_MAX 1.052795e+00\n",
      "time_step 11379 /SCORE 12.0 /rt 1.0 / Q_MAX 1.112022e+00\n",
      "time_step 11410 /SCORE 13.0 /rt 1.0 / Q_MAX 4.654559e-01\n",
      "time_step 11441 /SCORE 14.0 /rt 1.0 / Q_MAX 1.168672e+00\n",
      "time_step 11479 /SCORE 15.0 /rt 1.0 / Q_MAX 9.282122e-01\n",
      "time_step 11513 /SCORE 16.0 /rt 1.0 / Q_MAX 1.111273e+00\n",
      "time_step 11546 /SCORE 17.0 /rt 1.0 / Q_MAX 1.113861e-01\n",
      "time_step 11588 /SCORE 18.0 /rt -1.0 / Q_MAX 3.625799e-01\n",
      "time_step 11619 /SCORE 17.0 /rt 1.0 / Q_MAX 1.029151e+00\n",
      "time_step 11650 /SCORE 18.0 /rt 1.0 / Q_MAX 1.101393e+00\n",
      "time_step 11686 /SCORE 19.0 /rt 1.0 / Q_MAX 9.759569e-01\n",
      "time_step 11722 /SCORE 20.0 /rt -1 / Q_MAX -2.804944e-02\n",
      "time_step 11759 /SCORE 0.0 /rt -1.0 / Q_MAX 7.298245e-01\n",
      "time_step 11797 /SCORE -1.0 /rt 1.0 / Q_MAX 1.093116e+00\n",
      "time_step 11833 /SCORE 0.0 /rt 1.0 / Q_MAX 9.865530e-01\n",
      "time_step 11874 /SCORE 1.0 /rt 1.0 / Q_MAX 1.081306e+00\n",
      "time_step 11912 /SCORE 2.0 /rt 1.0 / Q_MAX 9.195772e-01\n",
      "time_step 11950 /SCORE 3.0 /rt 1.0 / Q_MAX 9.661847e-01\n",
      "time_step 11983 /SCORE 4.0 /rt 1.0 / Q_MAX 8.903134e-01\n",
      "time_step 12025 /SCORE 5.0 /rt -1.0 / Q_MAX -9.251983e-02\n",
      "time_step 12059 /SCORE 4.0 /rt -1 / Q_MAX -2.400440e-01\n",
      "time_step 12094 /SCORE 0.0 /rt 1.0 / Q_MAX 8.732812e-01\n",
      "time_step 12133 /SCORE 1.0 /rt 1.0 / Q_MAX 7.553620e-01\n",
      "time_step 12171 /SCORE 2.0 /rt 1.0 / Q_MAX 1.023939e+00\n",
      "time_step 12217 /SCORE 3.0 /rt -1.0 / Q_MAX 6.164234e-01\n",
      "time_step 12260 /SCORE 2.0 /rt 1.0 / Q_MAX 9.956246e-01\n",
      "time_step 12303 /SCORE 3.0 /rt 1.0 / Q_MAX 8.546979e-01\n",
      "time_step 12336 /SCORE 4.0 /rt 1.0 / Q_MAX 9.120803e-01\n",
      "time_step 12372 /SCORE 5.0 /rt 1.0 / Q_MAX 1.096864e+00\n",
      "time_step 12413 /SCORE 6.0 /rt 1.0 / Q_MAX 7.436634e-01\n",
      "time_step 12459 /SCORE 7.0 /rt -1.0 / Q_MAX 7.268959e-01\n",
      "time_step 12505 /SCORE 6.0 /rt -1 / Q_MAX 6.606314e-01\n",
      "time_step 12549 /SCORE 0.0 /rt 1.0 / Q_MAX 9.801224e-01\n",
      "time_step 12582 /SCORE 1.0 /rt 1.0 / Q_MAX 1.113807e+00\n",
      "time_step 12615 /SCORE 2.0 /rt 1.0 / Q_MAX 9.174465e-01\n",
      "time_step 12652 /SCORE 3.0 /rt -1.0 / Q_MAX 6.033278e-01\n",
      "time_step 12690 /SCORE 2.0 /rt 1.0 / Q_MAX 1.068726e+00\n",
      "time_step 12731 /SCORE 3.0 /rt 1.0 / Q_MAX 1.105086e+00\n",
      "time_step 12771 /SCORE 4.0 /rt 1.0 / Q_MAX 5.467878e-01\n",
      "time_step 12807 /SCORE 5.0 /rt 1.0 / Q_MAX 9.843784e-01\n",
      "time_step 12847 /SCORE 6.0 /rt 1.0 / Q_MAX 1.056587e+00\n",
      "time_step 12888 /SCORE 7.0 /rt 1.0 / Q_MAX 6.461876e-01\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "s, coeff, readout = createNetwork()\n",
    "vars_vals = trainNetwork(s, coeff, readout, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
